{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StyleGan Encoding for Children's Drawings\n",
    "\n",
    "- Using NVIDIA StyleGan: https://github.com/NVlabs/stylegan\n",
    "- Fine-tuning code: \n",
    "- Encoding code: https://github.com/Puzer/stylegan-encoder\n",
    "  - GOT https://github.com/iyaja/stylegan-encoder\n",
    "\n",
    "Assumes you have already done this setup and training [stylegan-finetune.ipynb](stylegan-finetune.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/iyaja/stylegan-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Augmentor to pre-process input drawings to be square (512x512):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess inputs\n",
    "\n",
    "Use Augmentor to pre-process input drawings to be square (512x512):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/child-art'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs():\n",
    "    \n",
    "    source = \"/home/jovyan/child-art/data/to_encode\"\n",
    "    dest = \"/home/jovyan/child-art/data/square\"\n",
    "\n",
    "    p = Augmentor.Pipeline(source, dest, save_format=\"JPEG\")\n",
    "    p.resize(probability=1.0, width=512, height=512)\n",
    "    p.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding into Latent Vector\n",
    "\n",
    "here is a reference https://github.com/iyaja/stylegan-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/child-art/stylegan-encoder\n"
     ]
    }
   ],
   "source": [
    "cd stylegan-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/child-art/stylegan-encoder'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python encode_images.py ../data/square/ generated_images/ latent_representations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do it inline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "from encoder.generator_model import Generator\n",
    "from encoder.perceptual_model import PerceptualModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_batches(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "src_dir = \"../data/square/\"\n",
    "generated_images_dir = \"../data/generated_images/\"\n",
    "dlatent_dir = \"../data/latent_representations/\"\n",
    "\n",
    "# training params\n",
    "batch_size = 1\n",
    "\n",
    "# perceptual model params\n",
    "image_size = 512\n",
    "lr = 1.0\n",
    "iterations = 1000\n",
    "\n",
    "# generator params\n",
    "randomize_noise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_images = [os.path.join(src_dir, x) for x in os.listdir(src_dir)]\n",
    "ref_images = list(filter(os.path.isfile, ref_images))\n",
    "\n",
    "if len(ref_images) == 0:\n",
    "    raise Exception('%s is empty' % src_dir)\n",
    "\n",
    "os.makedirs(generated_images_dir, exist_ok=True)\n",
    "os.makedirs(dlatent_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n",
    "# URL_FFHQ = 'https://s3-us-west-2.amazonaws.com/nanonets/blogs/karras2019stylegan-ffhq-1024x1024.pkl'\n",
    "\n",
    "\n",
    "# Initialize generator and perceptual model\n",
    "tflib.init_tf()\n",
    "\n",
    "# Flicker HQ not what I want\n",
    "# with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n",
    "#     generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
    "\n",
    "# Use my finetuned children's drawings stylegan\n",
    "model = \"../stylegan/results/00021-sgan-custom-2gpu/network-snapshot-011545.pkl\"\n",
    "with open(model, 'rb') as f:\n",
    "#     _G, _D, Gs = pickle.load(f)\n",
    "    _G, _D, Gs_network = pickle.load(f)\n",
    "\n",
    "    \n",
    "generator = Generator(Gs_network, batch_size, randomize_noise=randomize_noise)\n",
    "perceptual_model = PerceptualModel(image_size, layer=9, batch_size=batch_size)\n",
    "perceptual_model.build_perceptual_model(generator.generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize (only) dlatents by minimizing perceptual loss between reference and generated images in feature space\n",
    "for images_batch in tqdm(split_to_batches(ref_images, batch_size), total=len(ref_images)//batch_size):\n",
    "    names = [os.path.splitext(os.path.basename(x))[0] for x in images_batch]\n",
    "\n",
    "    perceptual_model.set_reference_images(images_batch)\n",
    "    op = perceptual_model.optimize(generator.dlatent_variable, iterations=iterations, learning_rate=lr)\n",
    "\n",
    "    pbar = tqdm(op, leave=False, total=iterations)\n",
    "    for loss in pbar:\n",
    "        pbar.set_description(' '.join(names)+' Loss: %.2f' % loss)\n",
    "    print(' '.join(names), ' loss:', loss)\n",
    "\n",
    "    # Generate images from found dlatents and save them\n",
    "    generated_images = generator.generate_images()\n",
    "    generated_dlatents = generator.get_dlatents()\n",
    "    for img_array, dlatent, img_name in zip(generated_images, generated_dlatents, names):\n",
    "        img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "        img.save(os.path.join(generated_images_dir, f'{img_name}.png'), 'PNG')\n",
    "        np.save(os.path.join(dlatent_dir, f'{img_name}.npy'), dlatent)\n",
    "        print(dlatent.shape, dlatent)\n",
    "\n",
    "    generator.reset_dlatents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

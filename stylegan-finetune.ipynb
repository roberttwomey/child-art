{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep tensorflow-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --user tensorflow-gpu==1.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --user tensorflow-estimator==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/NVlabs/stylegan.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/child-art/stylegan\n"
     ]
    }
   ],
   "source": [
    "cd stylegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download our preprocessed children's drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc http://roberttwomey.com/downloads/drawings_resized.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract training images from tarball:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -kxvf drawings_resized.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download latest model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc http://roberttwomey.com/downloads/network-snapshot-011125.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python dataset_tool.py create_from_images datasets/smalls/ stylegan/drawings_resized/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training_loop.py \n",
    "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "# 4.0 International License. To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "\"\"\"Main training script.\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "from dnnlib.tflib.autosummary import autosummary\n",
    "\n",
    "import config\n",
    "import train\n",
    "from training import dataset\n",
    "from training import misc\n",
    "from metrics import metric_base\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Just-in-time processing of training images before feeding them to the networks.\n",
    "\n",
    "def process_reals(x, lod, mirror_augment, drange_data, drange_net):\n",
    "    with tf.name_scope('ProcessReals'):\n",
    "        with tf.name_scope('DynamicRange'):\n",
    "            x = tf.cast(x, tf.float32)\n",
    "            x = misc.adjust_dynamic_range(x, drange_data, drange_net)\n",
    "        if mirror_augment:\n",
    "            with tf.name_scope('MirrorAugment'):\n",
    "                s = tf.shape(x)\n",
    "                mask = tf.random_uniform([s[0], 1, 1, 1], 0.0, 1.0)\n",
    "                mask = tf.tile(mask, [1, s[1], s[2], s[3]])\n",
    "                x = tf.where(mask < 0.5, x, tf.reverse(x, axis=[3]))\n",
    "        with tf.name_scope('FadeLOD'): # Smooth crossfade between consecutive levels-of-detail.\n",
    "            s = tf.shape(x)\n",
    "            y = tf.reshape(x, [-1, s[1], s[2]//2, 2, s[3]//2, 2])\n",
    "            y = tf.reduce_mean(y, axis=[3, 5], keepdims=True)\n",
    "            y = tf.tile(y, [1, 1, 1, 2, 1, 2])\n",
    "            y = tf.reshape(y, [-1, s[1], s[2], s[3]])\n",
    "            x = tflib.lerp(x, y, lod - tf.floor(lod))\n",
    "        with tf.name_scope('UpscaleLOD'): # Upscale to match the expected input/output size of the networks.\n",
    "            s = tf.shape(x)\n",
    "            factor = tf.cast(2 ** tf.floor(lod), tf.int32)\n",
    "            x = tf.reshape(x, [-1, s[1], s[2], 1, s[3], 1])\n",
    "            x = tf.tile(x, [1, 1, 1, factor, 1, factor])\n",
    "            x = tf.reshape(x, [-1, s[1], s[2] * factor, s[3] * factor])\n",
    "        return x\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Evaluate time-varying training parameters.\n",
    "\n",
    "def training_schedule(\n",
    "    cur_nimg,\n",
    "    training_set,\n",
    "    num_gpus, \n",
    "#     num_gpus = 2, \n",
    "    lod_initial_resolution  = 4,        # Image resolution used at the beginning.\n",
    "    lod_training_kimg       = 600,      # Thousands of real images to show before doubling the resolution.\n",
    "    lod_transition_kimg     = 600,      # Thousands of real images to show when fading in new layers.\n",
    "    minibatch_base          = 16,       # Maximum minibatch size, divided evenly among GPUs.\n",
    "    minibatch_dict          = {},       # Resolution-specific overrides.\n",
    "    max_minibatch_per_gpu   = {},       # Resolution-specific maximum minibatch size per GPU.\n",
    "    G_lrate_base            = 0.001,    # Learning rate for the generator.\n",
    "    G_lrate_dict            = {},       # Resolution-specific overrides.\n",
    "    D_lrate_base            = 0.001,    # Learning rate for the discriminator.\n",
    "    D_lrate_dict            = {},       # Resolution-specific overrides.\n",
    "    lrate_rampup_kimg       = 0,        # Duration of learning rate ramp-up.\n",
    "    tick_kimg_base          = 160,      # Default interval of progress snapshots.\n",
    "    tick_kimg_dict          = {4: 160, 8:140, 16:120, 32:100, 64:80, 128:60, 256:40, 512:30, 1024:20}): # Resolution-specific overrides.\n",
    "\n",
    "    # Initialize result dict.\n",
    "    s = dnnlib.EasyDict()\n",
    "    s.kimg = cur_nimg / 1000.0\n",
    "\n",
    "    # Training phase.\n",
    "    phase_dur = lod_training_kimg + lod_transition_kimg\n",
    "    phase_idx = int(np.floor(s.kimg / phase_dur)) if phase_dur > 0 else 0\n",
    "    phase_kimg = s.kimg - phase_idx * phase_dur\n",
    "\n",
    "    # Level-of-detail and resolution.\n",
    "    s.lod = training_set.resolution_log2\n",
    "    s.lod -= np.floor(np.log2(lod_initial_resolution))\n",
    "    s.lod -= phase_idx\n",
    "    if lod_transition_kimg > 0:\n",
    "        s.lod -= max(phase_kimg - lod_training_kimg, 0.0) / lod_transition_kimg\n",
    "    s.lod = max(s.lod, 0.0)\n",
    "    s.resolution = 2 ** (training_set.resolution_log2 - int(np.floor(s.lod)))\n",
    "\n",
    "    # Minibatch size.\n",
    "    s.minibatch = minibatch_dict.get(s.resolution, minibatch_base)\n",
    "    s.minibatch -= s.minibatch % num_gpus\n",
    "    if s.resolution in max_minibatch_per_gpu:\n",
    "        s.minibatch = min(s.minibatch, max_minibatch_per_gpu[s.resolution] * num_gpus)\n",
    "\n",
    "    # Learning rate.\n",
    "    s.G_lrate = G_lrate_dict.get(s.resolution, G_lrate_base)\n",
    "    s.D_lrate = D_lrate_dict.get(s.resolution, D_lrate_base)\n",
    "    if lrate_rampup_kimg > 0:\n",
    "        rampup = min(s.kimg / lrate_rampup_kimg, 1.0)\n",
    "        s.G_lrate *= rampup\n",
    "        s.D_lrate *= rampup\n",
    "\n",
    "    # Other parameters.\n",
    "    s.tick_kimg = tick_kimg_dict.get(s.resolution, tick_kimg_base)\n",
    "    return s\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Main training script.\n",
    "\n",
    "def training_loop(\n",
    "    submit_config,\n",
    "    G_args                  = {},       # Options for generator network.\n",
    "    D_args                  = {},       # Options for discriminator network.\n",
    "    G_opt_args              = {},       # Options for generator optimizer.\n",
    "    D_opt_args              = {},       # Options for discriminator optimizer.\n",
    "    G_loss_args             = {},       # Options for generator loss.\n",
    "    D_loss_args             = {},       # Options for discriminator loss.\n",
    "    dataset_args            = {},       # Options for dataset.load_dataset().\n",
    "    sched_args              = {},       # Options for train.TrainingSchedule.\n",
    "    grid_args               = {},       # Options for train.setup_snapshot_image_grid().\n",
    "    metric_arg_list         = [],       # Options for MetricGroup.\n",
    "    tf_config               = {},       # Options for tflib.init_tf().\n",
    "    G_smoothing_kimg        = 10.0,     # Half-life of the running average of generator weights.\n",
    "    D_repeats               = 1,        # How many times the discriminator is trained per G iteration.\n",
    "    minibatch_repeats       = 4,        # Number of minibatches to run before adjusting training parameters.\n",
    "    reset_opt_for_new_lod   = True,     # Reset optimizer internal state (e.g. Adam moments) when new layers are introduced?\n",
    "    total_kimg              = 15000,    # Total length of the training, measured in thousands of real images.\n",
    "    mirror_augment          = False,    # Enable mirror augment?\n",
    "    drange_net              = [-1,1],   # Dynamic range used when feeding image data to the networks.\n",
    "    image_snapshot_ticks    = 1,        # How often to export image snapshots?\n",
    "    network_snapshot_ticks  = 1,       # How often to export network snapshots?\n",
    "    save_tf_graph           = False,    # Include full TensorFlow computation graph in the tfevents file?\n",
    "    save_weight_histograms  = False,    # Include weight histograms in the tfevents file?\n",
    "    resume_run_id           = \"/home/jovyan/child-art/stylegan/network-snapshot-011125.pkl\",     # Run ID or network pkl to resume training from, None = start from scratch.\n",
    "    resume_snapshot         = None,     # Snapshot index to resume training from, None = autodetect.\n",
    "    resume_kimg             = 11125,      # Assumed training progress at the beginning. Affects reporting and training schedule.\n",
    "    resume_time             = 0.0):     # Assumed wallclock time at the beginning. Affects reporting.\n",
    "\n",
    "    # Initialize dnnlib and TensorFlow.\n",
    "    ctx = dnnlib.RunContext(submit_config, train)\n",
    "    tflib.init_tf(tf_config)\n",
    "\n",
    "    # Load training set.\n",
    "    training_set = dataset.load_dataset(data_dir=config.data_dir, verbose=True, **dataset_args)\n",
    "\n",
    "    # Construct networks.\n",
    "    with tf.device('/gpu:0'):\n",
    "        if resume_run_id is not None:\n",
    "            network_pkl = misc.locate_network_pkl(resume_run_id, resume_snapshot)\n",
    "            print('Loading networks from \"%s\"...' % network_pkl)\n",
    "            G, D, Gs = misc.load_pkl(network_pkl)\n",
    "        else:\n",
    "            print('Constructing networks...')\n",
    "            G = tflib.Network('G', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **G_args)\n",
    "            D = tflib.Network('D', num_channels=training_set.shape[0], resolution=training_set.shape[1], label_size=training_set.label_size, **D_args)\n",
    "            Gs = G.clone('Gs')\n",
    "    G.print_layers(); D.print_layers()\n",
    "\n",
    "    print('Building TensorFlow graph...')\n",
    "    with tf.name_scope('Inputs'), tf.device('/cpu:0'):\n",
    "        lod_in          = tf.placeholder(tf.float32, name='lod_in', shape=[])\n",
    "        lrate_in        = tf.placeholder(tf.float32, name='lrate_in', shape=[])\n",
    "        minibatch_in    = tf.placeholder(tf.int32, name='minibatch_in', shape=[])\n",
    "        minibatch_split = minibatch_in // submit_config.num_gpus\n",
    "        Gs_beta         = 0.5 ** tf.div(tf.cast(minibatch_in, tf.float32), G_smoothing_kimg * 1000.0) if G_smoothing_kimg > 0.0 else 0.0\n",
    "\n",
    "    G_opt = tflib.Optimizer(name='TrainG', learning_rate=lrate_in, **G_opt_args)\n",
    "    D_opt = tflib.Optimizer(name='TrainD', learning_rate=lrate_in, **D_opt_args)\n",
    "    for gpu in range(submit_config.num_gpus):\n",
    "        with tf.name_scope('GPU%d' % gpu), tf.device('/gpu:%d' % gpu):\n",
    "            G_gpu = G if gpu == 0 else G.clone(G.name + '_shadow')\n",
    "            D_gpu = D if gpu == 0 else D.clone(D.name + '_shadow')\n",
    "            lod_assign_ops = [tf.assign(G_gpu.find_var('lod'), lod_in), tf.assign(D_gpu.find_var('lod'), lod_in)]\n",
    "            reals, labels = training_set.get_minibatch_tf()\n",
    "            reals = process_reals(reals, lod_in, mirror_augment, training_set.dynamic_range, drange_net)\n",
    "            with tf.name_scope('G_loss'), tf.control_dependencies(lod_assign_ops):\n",
    "                G_loss = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=G_opt, training_set=training_set, minibatch_size=minibatch_split, **G_loss_args)\n",
    "            with tf.name_scope('D_loss'), tf.control_dependencies(lod_assign_ops):\n",
    "                D_loss = dnnlib.util.call_func_by_name(G=G_gpu, D=D_gpu, opt=D_opt, training_set=training_set, minibatch_size=minibatch_split, reals=reals, labels=labels, **D_loss_args)\n",
    "            G_opt.register_gradients(tf.reduce_mean(G_loss), G_gpu.trainables)\n",
    "            D_opt.register_gradients(tf.reduce_mean(D_loss), D_gpu.trainables)\n",
    "    G_train_op = G_opt.apply_updates()\n",
    "    D_train_op = D_opt.apply_updates()\n",
    "\n",
    "    Gs_update_op = Gs.setup_as_moving_average_of(G, beta=Gs_beta)\n",
    "    with tf.device('/gpu:0'):\n",
    "        try:\n",
    "            peak_gpu_mem_op = tf.contrib.memory_stats.MaxBytesInUse()\n",
    "        except tf.errors.NotFoundError:\n",
    "            peak_gpu_mem_op = tf.constant(0)\n",
    "\n",
    "    print('Setting up snapshot image grid...')\n",
    "    grid_size, grid_reals, grid_labels, grid_latents = misc.setup_snapshot_image_grid(G, training_set, **grid_args)\n",
    "    sched = training_schedule(cur_nimg=total_kimg*1000, training_set=training_set, num_gpus=submit_config.num_gpus, **sched_args)\n",
    "    grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch//submit_config.num_gpus)\n",
    "\n",
    "    print('Setting up run dir...')\n",
    "    misc.save_image_grid(grid_reals, os.path.join(submit_config.run_dir, 'reals.png'), drange=training_set.dynamic_range, grid_size=grid_size)\n",
    "    misc.save_image_grid(grid_fakes, os.path.join(submit_config.run_dir, 'fakes%06d.png' % resume_kimg), drange=drange_net, grid_size=grid_size)\n",
    "    summary_log = tf.summary.FileWriter(submit_config.run_dir)\n",
    "    if save_tf_graph:\n",
    "        summary_log.add_graph(tf.get_default_graph())\n",
    "    if save_weight_histograms:\n",
    "        G.setup_weight_histograms(); D.setup_weight_histograms()\n",
    "    metrics = metric_base.MetricGroup(metric_arg_list)\n",
    "\n",
    "    print('Training...\\n')\n",
    "    ctx.update('', cur_epoch=resume_kimg, max_epoch=total_kimg)\n",
    "    maintenance_time = ctx.get_last_update_interval()\n",
    "    cur_nimg = int(resume_kimg * 1000)\n",
    "    cur_tick = 0\n",
    "    tick_start_nimg = cur_nimg\n",
    "    prev_lod = -1.0\n",
    "    while cur_nimg < total_kimg * 1000:\n",
    "        if ctx.should_stop(): break\n",
    "\n",
    "        # Choose training parameters and configure training ops.\n",
    "        sched = training_schedule(cur_nimg=cur_nimg, training_set=training_set, num_gpus=submit_config.num_gpus, **sched_args)\n",
    "        training_set.configure(sched.minibatch // submit_config.num_gpus, sched.lod)\n",
    "        if reset_opt_for_new_lod:\n",
    "            if np.floor(sched.lod) != np.floor(prev_lod) or np.ceil(sched.lod) != np.ceil(prev_lod):\n",
    "                G_opt.reset_optimizer_state(); D_opt.reset_optimizer_state()\n",
    "        prev_lod = sched.lod\n",
    "\n",
    "        # Run training ops.\n",
    "        for _mb_repeat in range(minibatch_repeats):\n",
    "            for _D_repeat in range(D_repeats):\n",
    "                tflib.run([D_train_op, Gs_update_op], {lod_in: sched.lod, lrate_in: sched.D_lrate, minibatch_in: sched.minibatch})\n",
    "                cur_nimg += sched.minibatch\n",
    "            tflib.run([G_train_op], {lod_in: sched.lod, lrate_in: sched.G_lrate, minibatch_in: sched.minibatch})\n",
    "\n",
    "        # Perform maintenance tasks once per tick.\n",
    "        done = (cur_nimg >= total_kimg * 1000)\n",
    "        if cur_nimg >= tick_start_nimg + sched.tick_kimg * 1000 or done:\n",
    "            cur_tick += 1\n",
    "            tick_kimg = (cur_nimg - tick_start_nimg) / 1000.0\n",
    "            tick_start_nimg = cur_nimg\n",
    "            tick_time = ctx.get_time_since_last_update()\n",
    "            total_time = ctx.get_time_since_start() + resume_time\n",
    "\n",
    "            # Report progress.\n",
    "            print('tick %-5d kimg %-8.1f lod %-5.2f minibatch %-4d time %-12s sec/tick %-7.1f sec/kimg %-7.2f maintenance %-6.1f gpumem %-4.1f' % (\n",
    "                autosummary('Progress/tick', cur_tick),\n",
    "                autosummary('Progress/kimg', cur_nimg / 1000.0),\n",
    "                autosummary('Progress/lod', sched.lod),\n",
    "                autosummary('Progress/minibatch', sched.minibatch),\n",
    "                dnnlib.util.format_time(autosummary('Timing/total_sec', total_time)),\n",
    "                autosummary('Timing/sec_per_tick', tick_time),\n",
    "                autosummary('Timing/sec_per_kimg', tick_time / tick_kimg),\n",
    "                autosummary('Timing/maintenance_sec', maintenance_time),\n",
    "                autosummary('Resources/peak_gpu_mem_gb', peak_gpu_mem_op.eval() / 2**30)))\n",
    "            autosummary('Timing/total_hours', total_time / (60.0 * 60.0))\n",
    "            autosummary('Timing/total_days', total_time / (24.0 * 60.0 * 60.0))\n",
    "\n",
    "            # Save snapshots.\n",
    "            if cur_tick % image_snapshot_ticks == 0 or done:\n",
    "                grid_fakes = Gs.run(grid_latents, grid_labels, is_validation=True, minibatch_size=sched.minibatch//submit_config.num_gpus)\n",
    "                misc.save_image_grid(grid_fakes, os.path.join(submit_config.run_dir, 'fakes%06d.png' % (cur_nimg // 1000)), drange=drange_net, grid_size=grid_size)\n",
    "            if cur_tick % network_snapshot_ticks == 0 or done or cur_tick == 1:\n",
    "                pkl = os.path.join(submit_config.run_dir, 'network-snapshot-%06d.pkl' % (cur_nimg // 1000))\n",
    "                misc.save_pkl((G, D, Gs), pkl)\n",
    "                metrics.run(pkl, run_dir=submit_config.run_dir, num_gpus=submit_config.num_gpus, tf_config=tf_config)\n",
    "\n",
    "            # Update summaries and RunContext.\n",
    "            metrics.update_autosummaries()\n",
    "            tflib.autosummary.save_summaries(summary_log, cur_nimg)\n",
    "            ctx.update('%.2f' % sched.lod, cur_epoch=cur_nimg // 1000, max_epoch=total_kimg)\n",
    "            maintenance_time = ctx.get_last_update_interval() - tick_time\n",
    "\n",
    "    # Write final results.\n",
    "    misc.save_pkl((G, D, Gs), os.path.join(submit_config.run_dir, 'network-final.pkl'))\n",
    "    summary_log.close()\n",
    "\n",
    "    ctx.close()\n",
    "\n",
    "#----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Main Training\n",
    "\n",
    "run this from the stylegan directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the run dir: results/00014-sgan-custom-2gpu\n",
      "Copying files to the run dir\n",
      "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Streaming data using training.dataset.TFRecordDataset...\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:75: The name tf.python_io.TFRecordOptions is deprecated. Please use tf.io.TFRecordOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:75: The name tf.python_io.TFRecordCompressionType is deprecated. Please use tf.compat.v1.python_io.TFRecordCompressionType instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:76: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:114: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:196: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:200: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:132: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:132: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/dataset.py:132: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "Dataset shape = [3, 512, 512]\n",
      "Dynamic range = [0, 255]\n",
      "Label size    = 0\n",
      "Loading networks from \"/home/jovyan/child-art/stylegan/network-snapshot-011125.pkl\"...\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/network.py:150: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/tfutil.py:76: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/network.py:151: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/network.py:182: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "\n",
      "G                             Params    OutputShape         WeightShape     \n",
      "---                           ---       ---                 ---             \n",
      "latents_in                    -         (?, 512)            -               \n",
      "labels_in                     -         (?, 0)              -               \n",
      "lod                           -         ()                  -               \n",
      "dlatent_avg                   -         (512,)              -               \n",
      "G_mapping/latents_in          -         (?, 512)            -               \n",
      "G_mapping/labels_in           -         (?, 0)              -               \n",
      "G_mapping/PixelNorm           -         (?, 512)            -               \n",
      "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
      "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
      "G_mapping/dlatents_out        -         (?, 16, 512)        -               \n",
      "Truncation                    -         (?, 16, 512)        -               \n",
      "G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n",
      "G_synthesis/4x4/Const         534528    (?, 512, 4, 4)      (512,)          \n",
      "G_synthesis/4x4/Conv          2885632   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod7        1539      (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
      "G_synthesis/8x8/Conv0_up      2885632   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/8x8/Conv1         2885632   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod6        1539      (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
      "G_synthesis/Upscale2D         -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/Grow_lod6         -         (?, 3, 8, 8)        -               \n",
      "G_synthesis/16x16/Conv0_up    2885632   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/16x16/Conv1       2885632   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod5        1539      (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
      "G_synthesis/Upscale2D_1       -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/Grow_lod5         -         (?, 3, 16, 16)      -               \n",
      "G_synthesis/32x32/Conv0_up    2885632   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/32x32/Conv1       2885632   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "G_synthesis/ToRGB_lod4        1539      (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
      "G_synthesis/Upscale2D_2       -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/Grow_lod4         -         (?, 3, 32, 32)      -               \n",
      "G_synthesis/64x64/Conv0_up    1442816   (?, 256, 64, 64)    (3, 3, 512, 256)\n",
      "G_synthesis/64x64/Conv1       852992    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "G_synthesis/ToRGB_lod3        771       (?, 3, 64, 64)      (1, 1, 256, 3)  \n",
      "G_synthesis/Upscale2D_3       -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/Grow_lod3         -         (?, 3, 64, 64)      -               \n",
      "G_synthesis/128x128/Conv0_up  426496    (?, 128, 128, 128)  (3, 3, 256, 128)\n",
      "G_synthesis/128x128/Conv1     279040    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "G_synthesis/ToRGB_lod2        387       (?, 3, 128, 128)    (1, 1, 128, 3)  \n",
      "G_synthesis/Upscale2D_4       -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/Grow_lod2         -         (?, 3, 128, 128)    -               \n",
      "G_synthesis/256x256/Conv0_up  139520    (?, 64, 256, 256)   (3, 3, 128, 64) \n",
      "G_synthesis/256x256/Conv1     102656    (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "G_synthesis/ToRGB_lod1        195       (?, 3, 256, 256)    (1, 1, 64, 3)   \n",
      "G_synthesis/Upscale2D_5       -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/Grow_lod1         -         (?, 3, 256, 256)    -               \n",
      "G_synthesis/512x512/Conv0_up  51328     (?, 32, 512, 512)   (3, 3, 64, 32)  \n",
      "G_synthesis/512x512/Conv1     42112     (?, 32, 512, 512)   (3, 3, 32, 32)  \n",
      "G_synthesis/ToRGB_lod0        99        (?, 3, 512, 512)    (1, 1, 32, 3)   \n",
      "G_synthesis/Upscale2D_6       -         (?, 3, 512, 512)    -               \n",
      "G_synthesis/Grow_lod0         -         (?, 3, 512, 512)    -               \n",
      "G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n",
      "G_synthesis/lod               -         ()                  -               \n",
      "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
      "G_synthesis/noise1            -         (1, 1, 4, 4)        -               \n",
      "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
      "G_synthesis/noise3            -         (1, 1, 8, 8)        -               \n",
      "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
      "G_synthesis/noise5            -         (1, 1, 16, 16)      -               \n",
      "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
      "G_synthesis/noise7            -         (1, 1, 32, 32)      -               \n",
      "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
      "G_synthesis/noise9            -         (1, 1, 64, 64)      -               \n",
      "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
      "G_synthesis/noise11           -         (1, 1, 128, 128)    -               \n",
      "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
      "G_synthesis/noise13           -         (1, 1, 256, 256)    -               \n",
      "G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n",
      "G_synthesis/noise15           -         (1, 1, 512, 512)    -               \n",
      "images_out                    -         (?, 3, 512, 512)    -               \n",
      "---                           ---       ---                 ---             \n",
      "Total                         26179768                                      \n",
      "\n",
      "\n",
      "D                    Params    OutputShape         WeightShape     \n",
      "---                  ---       ---                 ---             \n",
      "images_in            -         (?, 3, 512, 512)    -               \n",
      "labels_in            -         (?, 0)              -               \n",
      "lod                  -         ()                  -               \n",
      "FromRGB_lod0         128       (?, 32, 512, 512)   (1, 1, 3, 32)   \n",
      "512x512/Conv0        9248      (?, 32, 512, 512)   (3, 3, 32, 32)  \n",
      "512x512/Conv1_down   18496     (?, 64, 256, 256)   (3, 3, 32, 64)  \n",
      "Downscale2D          -         (?, 3, 256, 256)    -               \n",
      "FromRGB_lod1         256       (?, 64, 256, 256)   (1, 1, 3, 64)   \n",
      "Grow_lod0            -         (?, 64, 256, 256)   -               \n",
      "256x256/Conv0        36928     (?, 64, 256, 256)   (3, 3, 64, 64)  \n",
      "256x256/Conv1_down   73856     (?, 128, 128, 128)  (3, 3, 64, 128) \n",
      "Downscale2D_1        -         (?, 3, 128, 128)    -               \n",
      "FromRGB_lod2         512       (?, 128, 128, 128)  (1, 1, 3, 128)  \n",
      "Grow_lod1            -         (?, 128, 128, 128)  -               \n",
      "128x128/Conv0        147584    (?, 128, 128, 128)  (3, 3, 128, 128)\n",
      "128x128/Conv1_down   295168    (?, 256, 64, 64)    (3, 3, 128, 256)\n",
      "Downscale2D_2        -         (?, 3, 64, 64)      -               \n",
      "FromRGB_lod3         1024      (?, 256, 64, 64)    (1, 1, 3, 256)  \n",
      "Grow_lod2            -         (?, 256, 64, 64)    -               \n",
      "64x64/Conv0          590080    (?, 256, 64, 64)    (3, 3, 256, 256)\n",
      "64x64/Conv1_down     1180160   (?, 512, 32, 32)    (3, 3, 256, 512)\n",
      "Downscale2D_3        -         (?, 3, 32, 32)      -               \n",
      "FromRGB_lod4         2048      (?, 512, 32, 32)    (1, 1, 3, 512)  \n",
      "Grow_lod3            -         (?, 512, 32, 32)    -               \n",
      "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
      "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "Downscale2D_4        -         (?, 3, 16, 16)      -               \n",
      "FromRGB_lod5         2048      (?, 512, 16, 16)    (1, 1, 3, 512)  \n",
      "Grow_lod4            -         (?, 512, 16, 16)    -               \n",
      "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
      "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "Downscale2D_5        -         (?, 3, 8, 8)        -               \n",
      "FromRGB_lod6         2048      (?, 512, 8, 8)      (1, 1, 3, 512)  \n",
      "Grow_lod5            -         (?, 512, 8, 8)      -               \n",
      "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
      "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
      "Downscale2D_6        -         (?, 3, 4, 4)        -               \n",
      "FromRGB_lod7         2048      (?, 512, 4, 4)      (1, 1, 3, 512)  \n",
      "Grow_lod6            -         (?, 512, 4, 4)      -               \n",
      "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
      "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
      "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
      "4x4/Dense1           513       (?, 1)              (512, 1)        \n",
      "scores_out           -         (?, 1)              -               \n",
      "---                  ---       ---                 ---             \n",
      "Total                23080225                                      \n",
      "\n",
      "Building TensorFlow graph...\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/training_loop.py:168: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/util.py:242: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/training_loop.py:34: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/loss.py:132: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/autosummary.py:61: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/autosummary.py:65: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/autosummary.py:65: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/dnnlib/tflib/optimizer.py:98: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Setting up snapshot image grid...\n",
      "Setting up run dir...\n",
      "WARNING:tensorflow:From /home/jovyan/child-art/stylegan/training/training_loop.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Training...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "# 4.0 International License. To view a copy of this license, visit\n",
    "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "\n",
    "\"\"\"Main entry point for training StyleGAN and ProGAN networks.\"\"\"\n",
    "\n",
    "import copy\n",
    "import dnnlib\n",
    "from dnnlib import EasyDict\n",
    "\n",
    "import config\n",
    "from metrics import metric_base\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Official training configs for StyleGAN, targeted mainly for FFHQ.\n",
    "\n",
    "if 1:\n",
    "    desc          = 'sgan'                                                                 # Description string included in result subdir name.\n",
    "    train         = EasyDict(run_func_name='training.training_loop.training_loop')         # Options for training loop.\n",
    "    G             = EasyDict(func_name='training.networks_stylegan.G_style')               # Options for generator network.\n",
    "    D             = EasyDict(func_name='training.networks_stylegan.D_basic')               # Options for discriminator network.\n",
    "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for generator optimizer.\n",
    "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for discriminator optimizer.\n",
    "    G_loss        = EasyDict(func_name='training.loss.G_logistic_nonsaturating')           # Options for generator loss.\n",
    "    D_loss        = EasyDict(func_name='training.loss.D_logistic_simplegp', r1_gamma=10.0) # Options for discriminator loss.\n",
    "    dataset       = EasyDict()                                                             # Options for load_dataset().\n",
    "    sched         = EasyDict()                                                             # Options for TrainingSchedule.\n",
    "    grid          = EasyDict(size='4k', layout='random')                                   # Options for setup_snapshot_image_grid().\n",
    "    #metrics       = [metric_base.fid50k]                                                   # Options for MetricGroup.\n",
    "    submit_config = dnnlib.SubmitConfig()                                                  # Options for dnnlib.submit_run().\n",
    "    tf_config     = {'rnd.np_random_seed': 1000}                                           # Options for tflib.init_tf().\n",
    "\n",
    "    # Dataset.\n",
    "    desc += '-custom';     dataset = EasyDict(tfrecord_dir='smalls');              train.mirror_augment = True\n",
    "    #desc += '-celebahq'; dataset = EasyDict(tfrecord_dir='celebahq');          train.mirror_augment = True\n",
    "    #desc += '-bedroom';  dataset = EasyDict(tfrecord_dir='lsun-bedroom-full'); train.mirror_augment = False\n",
    "    #desc += '-car';      dataset = EasyDict(tfrecord_dir='lsun-car-512x384');  train.mirror_augment = False\n",
    "    #desc += '-cat';      dataset = EasyDict(tfrecord_dir='lsun-cat-full');     train.mirror_augment = False\n",
    "\n",
    "    # Number of GPUs.\n",
    "#     desc += '-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}\n",
    "    desc += '-2gpu'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}\n",
    "    #desc += '-4gpu'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
    "    #desc += '-8gpu'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
    "\n",
    "    # Default options.\n",
    "    train.total_kimg = 25000\n",
    "    sched.lod_initial_resolution = 8\n",
    "    sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "    sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
    "\n",
    "    # WGAN-GP loss for CelebA-HQ.\n",
    "    #desc += '-wgangp'; G_loss = EasyDict(func_name='training.loss.G_wgan'); D_loss = EasyDict(func_name='training.loss.D_wgan_gp'); sched.G_lrate_dict = {k: min(v, 0.002) for k, v in sched.G_lrate_dict.items()}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
    "\n",
    "    # Table 1.\n",
    "    #desc += '-tuned-baseline'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-add-mapping-and-styles'; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-remove-traditional-input'; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-add-noise-inputs'; G.style_mixing_prob = 0.0\n",
    "    #desc += '-mixing-regularization' # default\n",
    "\n",
    "    # Table 2.\n",
    "    #desc += '-mix0'; G.style_mixing_prob = 0.0\n",
    "    #desc += '-mix50'; G.style_mixing_prob = 0.5\n",
    "    #desc += '-mix90'; G.style_mixing_prob = 0.9 # default\n",
    "    #desc += '-mix100'; G.style_mixing_prob = 1.0\n",
    "\n",
    "    # Table 4.\n",
    "    #desc += '-traditional-0'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 0; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-traditional-8'; G.use_styles = False; G.use_pixel_norm = True; G.use_instance_norm = False; G.mapping_layers = 8; G.truncation_psi = None; G.const_input_layer = False; G.style_mixing_prob = 0.0; G.use_noise = False\n",
    "    #desc += '-stylebased-0'; G.mapping_layers = 0\n",
    "    #desc += '-stylebased-1'; G.mapping_layers = 1\n",
    "    #desc += '-stylebased-2'; G.mapping_layers = 2\n",
    "    #desc += '-stylebased-8'; G.mapping_layers = 8 # default\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Official training configs for Progressive GAN, targeted mainly for CelebA-HQ.\n",
    "\n",
    "if 0:\n",
    "    desc          = 'pgan'                                                         # Description string included in result subdir name.\n",
    "    train         = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
    "    G             = EasyDict(func_name='training.networks_progan.G_paper')         # Options for generator network.\n",
    "    D             = EasyDict(func_name='training.networks_progan.D_paper')         # Options for discriminator network.\n",
    "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
    "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
    "    G_loss        = EasyDict(func_name='training.loss.G_wgan')                     # Options for generator loss.\n",
    "    D_loss        = EasyDict(func_name='training.loss.D_wgan_gp')                  # Options for discriminator loss.\n",
    "    dataset       = EasyDict()                                                     # Options for load_dataset().\n",
    "    sched         = EasyDict()                                                     # Options for TrainingSchedule.\n",
    "    grid          = EasyDict(size='1080p', layout='random')                        # Options for setup_snapshot_image_grid().\n",
    "    #metrics       = [metric_base.fid50k]                                           # Options for MetricGroup.\n",
    "    submit_config = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
    "    tf_config     = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
    "\n",
    "    # Dataset (choose one).\n",
    "    #desc += '-celebahq';            dataset = EasyDict(tfrecord_dir='celebahq'); train.mirror_augment = True\n",
    "    #desc += '-celeba';              dataset = EasyDict(tfrecord_dir='celeba'); train.mirror_augment = True\n",
    "    #desc += '-cifar10';             dataset = EasyDict(tfrecord_dir='cifar10')\n",
    "    #desc += '-cifar100';            dataset = EasyDict(tfrecord_dir='cifar100')\n",
    "    #desc += '-svhn';                dataset = EasyDict(tfrecord_dir='svhn')\n",
    "    #desc += '-mnist';               dataset = EasyDict(tfrecord_dir='mnist')\n",
    "    #desc += '-mnistrgb';            dataset = EasyDict(tfrecord_dir='mnistrgb')\n",
    "    #desc += '-syn1024rgb';          dataset = EasyDict(class_name='training.dataset.SyntheticDataset', resolution=1024, num_channels=3)\n",
    "    #desc += '-lsun-airplane';       dataset = EasyDict(tfrecord_dir='lsun-airplane-100k');       train.mirror_augment = True\n",
    "    #desc += '-lsun-bedroom';        dataset = EasyDict(tfrecord_dir='lsun-bedroom-100k');        train.mirror_augment = True\n",
    "    #desc += '-lsun-bicycle';        dataset = EasyDict(tfrecord_dir='lsun-bicycle-100k');        train.mirror_augment = True\n",
    "    #desc += '-lsun-bird';           dataset = EasyDict(tfrecord_dir='lsun-bird-100k');           train.mirror_augment = True\n",
    "    #desc += '-lsun-boat';           dataset = EasyDict(tfrecord_dir='lsun-boat-100k');           train.mirror_augment = True\n",
    "    #desc += '-lsun-bottle';         dataset = EasyDict(tfrecord_dir='lsun-bottle-100k');         train.mirror_augment = True\n",
    "    #desc += '-lsun-bridge';         dataset = EasyDict(tfrecord_dir='lsun-bridge-100k');         train.mirror_augment = True\n",
    "    #desc += '-lsun-bus';            dataset = EasyDict(tfrecord_dir='lsun-bus-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-car';            dataset = EasyDict(tfrecord_dir='lsun-car-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-cat';            dataset = EasyDict(tfrecord_dir='lsun-cat-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-chair';          dataset = EasyDict(tfrecord_dir='lsun-chair-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-churchoutdoor';  dataset = EasyDict(tfrecord_dir='lsun-churchoutdoor-100k');  train.mirror_augment = True\n",
    "    #desc += '-lsun-classroom';      dataset = EasyDict(tfrecord_dir='lsun-classroom-100k');      train.mirror_augment = True\n",
    "    #desc += '-lsun-conferenceroom'; dataset = EasyDict(tfrecord_dir='lsun-conferenceroom-100k'); train.mirror_augment = True\n",
    "    #desc += '-lsun-cow';            dataset = EasyDict(tfrecord_dir='lsun-cow-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-diningroom';     dataset = EasyDict(tfrecord_dir='lsun-diningroom-100k');     train.mirror_augment = True\n",
    "    #desc += '-lsun-diningtable';    dataset = EasyDict(tfrecord_dir='lsun-diningtable-100k');    train.mirror_augment = True\n",
    "    #desc += '-lsun-dog';            dataset = EasyDict(tfrecord_dir='lsun-dog-100k');            train.mirror_augment = True\n",
    "    #desc += '-lsun-horse';          dataset = EasyDict(tfrecord_dir='lsun-horse-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-kitchen';        dataset = EasyDict(tfrecord_dir='lsun-kitchen-100k');        train.mirror_augment = True\n",
    "    #desc += '-lsun-livingroom';     dataset = EasyDict(tfrecord_dir='lsun-livingroom-100k');     train.mirror_augment = True\n",
    "    #desc += '-lsun-motorbike';      dataset = EasyDict(tfrecord_dir='lsun-motorbike-100k');      train.mirror_augment = True\n",
    "    #desc += '-lsun-person';         dataset = EasyDict(tfrecord_dir='lsun-person-100k');         train.mirror_augment = True\n",
    "    #desc += '-lsun-pottedplant';    dataset = EasyDict(tfrecord_dir='lsun-pottedplant-100k');    train.mirror_augment = True\n",
    "    #desc += '-lsun-restaurant';     dataset = EasyDict(tfrecord_dir='lsun-restaurant-100k');     train.mirror_augment = True\n",
    "    #desc += '-lsun-sheep';          dataset = EasyDict(tfrecord_dir='lsun-sheep-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-sofa';           dataset = EasyDict(tfrecord_dir='lsun-sofa-100k');           train.mirror_augment = True\n",
    "    #desc += '-lsun-tower';          dataset = EasyDict(tfrecord_dir='lsun-tower-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-train';          dataset = EasyDict(tfrecord_dir='lsun-train-100k');          train.mirror_augment = True\n",
    "    #desc += '-lsun-tvmonitor';      dataset = EasyDict(tfrecord_dir='lsun-tvmonitor-100k');      train.mirror_augment = True\n",
    "\n",
    "    # Conditioning & snapshot options.\n",
    "    #desc += '-cond'; dataset.max_label_size = 'full' # conditioned on full label\n",
    "    #desc += '-cond1'; dataset.max_label_size = 1 # conditioned on first component of the label\n",
    "    #desc += '-g4k'; grid.size = '4k'\n",
    "    #desc += '-grpc'; grid.layout = 'row_per_class'\n",
    "\n",
    "    # Config presets (choose one).\n",
    "    #desc += '-preset-v1-1gpu'; submit_config.num_gpus = 1; D.mbstd_group_size = 16; sched.minibatch_base = 16; sched.minibatch_dict = {256: 14, 512: 6, 1024: 3}; sched.lod_training_kimg = 800; sched.lod_transition_kimg = 800; train.total_kimg = 19000\n",
    "    #desc += '-preset-v2-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}; sched.G_lrate_dict = {1024: 0.0015}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "    #desc += '-preset-v2-2gpus'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}; sched.G_lrate_dict = {512: 0.0015, 1024: 0.002}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "    #desc += '-preset-v2-4gpus'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}; sched.G_lrate_dict = {256: 0.0015, 512: 0.002, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "    #desc += '-preset-v2-8gpus'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}; sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
    "\n",
    "    # Numerical precision (choose one).\n",
    "    #desc += '-fp32'; sched.max_minibatch_per_gpu = {256: 16, 512: 8, 1024: 4}\n",
    "    #desc += '-fp16'; G.dtype = 'float16'; D.dtype = 'float16'; G.pixelnorm_epsilon=1e-4; G_opt.use_loss_scaling = True; D_opt.use_loss_scaling = True; sched.max_minibatch_per_gpu = {512: 16, 1024: 8}\n",
    "\n",
    "    # Disable individual features.\n",
    "    #desc += '-nogrowing'; sched.lod_initial_resolution = 1024; sched.lod_training_kimg = 0; sched.lod_transition_kimg = 0; train.total_kimg = 10000\n",
    "    #desc += '-nopixelnorm'; G.use_pixelnorm = False\n",
    "    #desc += '-nowscale'; G.use_wscale = False; D.use_wscale = False\n",
    "    #desc += '-noleakyrelu'; G.use_leakyrelu = False\n",
    "    #desc += '-nosmoothing'; train.G_smoothing_kimg = 0.0\n",
    "    #desc += '-norepeat'; train.minibatch_repeats = 1\n",
    "    #desc += '-noreset'; train.reset_opt_for_new_lod = False\n",
    "\n",
    "    # Special modes.\n",
    "    #desc += '-BENCHMARK'; sched.lod_initial_resolution = 4; sched.lod_training_kimg = 3; sched.lod_transition_kimg = 3; train.total_kimg = (8*2+1)*3; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
    "    #desc += '-BENCHMARK0'; sched.lod_initial_resolution = 1024; train.total_kimg = 10; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
    "    #desc += '-VERBOSE'; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1; train.network_snapshot_ticks = 100\n",
    "    #desc += '-GRAPH'; train.save_tf_graph = True\n",
    "    #desc += '-HIST'; train.save_weight_histograms = True\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Main entry point for training.\n",
    "# Calls the function indicated by 'train' using the selected options.\n",
    "\n",
    "def main():\n",
    "    kwargs = EasyDict(train)\n",
    "    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
    "    kwargs.update(dataset_args=dataset, sched_args=sched, grid_args=grid, tf_config=tf_config)\n",
    "    kwargs.submit_config = copy.deepcopy(submit_config)\n",
    "    kwargs.submit_config.run_dir_root = dnnlib.submission.submit.get_template_from_path(config.result_dir)\n",
    "    kwargs.submit_config.run_dir_ignore += config.run_dir_ignore\n",
    "    kwargs.submit_config.run_desc = desc\n",
    "    dnnlib.submit_run(**kwargs)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
